{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2016-09-21: Introduction to scikit-learn\n",
    "This tutorial is based on resources from http://scikit-learn.org and the scikit-learn tutorial at Scipy 2013 by Gael Varoquaux, Jake VanderPlas and Olivier Grisel (https://www.youtube.com/watch?v=r4bRUvvlaBw and https://github.com/jakevdp/sklearn_scipy2013).\n",
    "\n",
    "Machine learning is about creating models from data: for that reason, we’ll start by discussing how data can be represented in order to be understood by the computer. Along with this, we’ll build on our matplotlib examples from the previous lab and show some examples of how to visualize data.\n",
    "\n",
    "Most machine learning algorithms implemented in scikit-learn expect data to be stored in a two-dimensional array, of shape `(n_samples, n_features)`. The arrays can be either NumPy arrays, or in some cases `scipy.sparse` matrices. The number of features must be fixed in advance. However it can be very high dimensional (e.g. millions of features) with most of them being zeros for a given sample. This is a case where `scipy.sparse` matrices can be useful, in that they are much more memory-efficient than NumPy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The endometrium vs uterus cancer data\n",
    "\n",
    "For this lab and many of the coming ones, we will work with gene expression data measured on endometrium and ovary tumors. The data originally comes from http://gemler.fzv.uni-mb.si/index.php but has been downsized so that it is easier to work with in our labs.\n",
    "\n",
    "The data we will work with contains the expression of 3,000 genes, measured for 61 endometrium tumors and 123 uterus tumors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "The data is stored in a CSV file, `small_Endometrium_Uterus.csv`. Many utilities can be used to read CSV files, including the `csv` module and the `pandas` module (that is meant for data mining). We will focus on using numpy directly.\n",
    "\n",
    "A quick look at the file shows us that\n",
    "* its first line is a header\n",
    "* each of its lines is a tumor sample. \n",
    "* the first column of each line is the tumor sample's ID\n",
    "* the last column of each line is the type of tissue (Endometrium or Uterus)\n",
    "* all columns in between give the expression of one gene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the gene expression data\n",
    "X = np.loadtxt('data/small_Endometrium_Uterus.csv',  delimiter=',', \n",
    "               skiprows=1, usecols=range(1, 3001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the labels\n",
    "y = np.loadtxt('data/small_Endometrium_Uterus.csv', delimiter=',', \n",
    "               skiprows=1, usecols=[3001], dtype='string')\n",
    "\n",
    "# Convert 'Endometrium' to 0 and 'Uterus' to 1\n",
    "y = np.where(y=='Endometrium', 0, 1)\n",
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We could have done the previous operation in one step, using a converter\n",
    "y = np.loadtxt('data/small_Endometrium_Uterus.csv', delimiter=',', skiprows=1, usecols=[3001], \n",
    "               converters={3001: lambda s: 0 if s=='Endometrium' else 1}, dtype='int')\n",
    "print y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load pylab\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize the data across 2 of its axes\n",
    "idx_1 = 0 # first axis (or gene)\n",
    "idx_2 = 1 # second axis (or gene)\n",
    "plt.scatter(X[y==0, idx_1], X[y==0, idx_2], # y==0 gives the indices of the columns for which y is equal to 0\n",
    "            color='blue', label='Endometrium')\n",
    "plt.scatter(X[y==1, idx_1], X[y==1, idx_2], color='orange', label='Uterus')\n",
    "plt.legend(scatterpoints=1)\n",
    "plt.xlabel('Gene %d' % idx_1, fontsize=14)\n",
    "plt.ylabel('Gene %d' % idx_2, fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with the values of `idx_1` and `idx_2`. What do you notice about the range of the values taken by the different genes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gaussian Naive Bayes\n",
    "\n",
    "Documentation: http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html \n",
    "\n",
    "Our goal here is to try to classify points between endometrium and uterus tumors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a Gaussian Naive Bayes classifier i.e. an instance of GaussianNB\n",
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit the classifier to the data\n",
    "gnb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict on the same data\n",
    "y_pred = gnb.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute the number of mislabeled genes\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % \\\n",
    "      (X.shape[0], (y != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Score the model\n",
    "from sklearn import metrics\n",
    "print \"Accuracy: %.3f\" % metrics.accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve\n",
    "\n",
    "Building an ROC curve requires to use the probability estimates for the test data points *before* they are thresholded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get probability estimates\n",
    "y_prob = gnb.predict_proba(X)\n",
    "print y_prob.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** `y_prob` returns two values for each data point because it returns one probability estimate per class for each data point. The order in which the classes appear are given by `gnb.classes_`. How do you get the 1-dimensional array that only contains the estimated probability for each point to belong to the positive class?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, y_prob[:, 1], pos_label=1)\n",
    "\n",
    "# Area under the ROC curve\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(fpr, tpr, '-', color='orange', label='AUC = %0.3f' % auc)\n",
    "\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "plt.title('ROC curve: Gaussian Naive Bayes', fontsize=16)\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What are the parameters of the model we have trained? How many of them are they? How can you access them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is it problematic to have evaluated our classifier on the training data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up a stratified 10-fold cross-validation\n",
    "from sklearn import cross_validation\n",
    "folds = cross_validation.StratifiedKFold(y, 10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is one way to access the training and test points\n",
    "for ix, (tr, te) in enumerate(folds):\n",
    "    print \"Fold %d\" % ix\n",
    "    print \"\\t %d training points\" % len(tr)\n",
    "    print \"\\t %d test points\" % len(te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Create a loop that goes through all 10 folds and for each fold:\n",
    "* trains a Gaussian Naive Bayes model on the training data\n",
    "* uses this model to make predictions on the test data. \n",
    "In this fashion you should be able to form *a single vector of predictions* `y_prob_cv` (as each point from the data appears once as a test point in the cross-validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Evaluate the performance of your model (accuracy, AUC, ROC-AUC). How does it compare to the one you previously obtained?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** The `sklearn.cross_validation` module provides some utilities to make cross-validated predictions. Compare the results you obtained to what they return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "cv_aucs = cross_validation.cross_val_score(gnb, X, y, cv=folds, scoring='roc_auc')\n",
    "print np.mean(cv_aucs)\n",
    "\n",
    "# Note that averaging the AUCs obtained over 10 folds is not exactly the same as \n",
    "# globally computing the AUC for the predictions made within the cross-validation loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "print \"Cross-validated accuracy: %.3f\" % \\\n",
    "    metrics.accuracy_score(y, cross_validation.cross_val_predict(gnb, X, y, cv=folds))\n",
    "# This should return the same as \n",
    "print \"Cross-validated accuracy: %.3f\" % metrics.accuracy_score(y, np.where(y_prob_cv > 0.5, 1, 0))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Iris data\n",
    "As an example of a simple dataset, we’re going to take a look at the Iris data stored by scikit-learn. The data is a classical UCI dataset and consists of measurements of three different species of irises.\n",
    "\n",
    "You can learn more about this data set here: https://en.wikipedia.org/wiki/Iris_flower_data_set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What features could you use to represent irises in order to decide to which of the three species they belong?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn has a very straightforward set of data on these iris species. The data consist of the following:\n",
    "* Features in the Iris dataset:\n",
    "    * sepal length in cm\n",
    "    * sepal width in cm\n",
    "    * petal length in cm\n",
    "    * petal width in cm\n",
    "* Target classes to predict:\n",
    "    * Iris setosa\n",
    "    * Iris versicolour\n",
    "    * Iris virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# iris is a Bunch object\n",
    "# see what’s available in iris:\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The features of each sample flower are stored in the data\n",
    "# attribute of the dataset:\n",
    "n_samples, n_features = iris.data.shape\n",
    "print n_samples\n",
    "print n_features\n",
    "print iris.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The information about the class of each sample is stored in the target\n",
    "# attribute of the dataset:\n",
    "print iris.target.shape\n",
    "print iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The names of the classes are stored in the last attribute,\n",
    "# namely target_names:\n",
    "print iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This data is four dimensional, but we can visualize two of the dimensions at a time using a simple scatter-plot.\n",
    "%pylab inline\n",
    "idx_1 = 0 # index of the first feature to plot\n",
    "idx_2 = 1 # index of the second feature to plot\n",
    "\n",
    "# Scatterplot\n",
    "plt.scatter(iris.data[:, idx_1], iris.data[:, idx_2], s=40, c=iris.target)\n",
    "\n",
    "# Create a formatter that will label the colorbar with the correct target names.\n",
    "# lambda i, *args: iris.target_names[int(i)] converts an index i into the corresponding label\n",
    "formatter = plt.FuncFormatter(lambda i, *args: iris.target_names[int(i)])\n",
    "plt.colorbar(ticks=[0, 1, 2], format=formatter)\n",
    "\n",
    "plt.xlabel(iris.feature_names[idx_1], fontsize=14)\n",
    "plt.ylabel(iris.feature_names[idx_2], fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Change `idx_1` and `idx_2`, and find (visually) which combination of two parameters best separates the three classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Create a Gaussian Naive Bayes classifier and train it on the Iris data, using only the two features you have identified in the previous question. How many instances are misclassified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Digits data\n",
    "\n",
    "Let us now take a look at the Digits dataset. This data set, also very classical, contains images of hand-written digits, each labeled with the corresponding digit. This means there are 10 classes in this data. Each image has been compressed into an 8 × 8 matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the digits data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the digits dataset\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Each data point is an image, and has for target the number it represents\n",
    "print np.unique(digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the difference between `digits.data` and `digits.images`? Actually, `digits.data` is simply `digits.images` reshaped, with the 8×8 array flattened out in a 64-dimensional vector. These two representations can exist without needing to fully duplicate the data, and hence the memory overhead is very small. Indeed, the two arrays, although they have different shapes, point at the same memory block. To check this is true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check the two arrays contain identical data\n",
    "print np.all(digits.images.reshape((1797, 64)) == digits.data)\n",
    "\n",
    "# check the two arrays point to the same memory address\n",
    "print digits.data.__array_interface__['data']\n",
    "print digits.images.__array_interface__['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the digits data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up a figure that will contain multiple subplots\n",
    "fig = plt.figure(figsize=(6, 6)) # figure size in inches\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "# plot the 49 first digits: each image is 8 by 8 pixels\n",
    "for i in range(49):\n",
    "    ax = fig.add_subplot(7, 7, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(digits.images[i], cmap=plt.cm.Greys, interpolation='nearest')\n",
    "    \n",
    "    # label the image with the target value\n",
    "    ax.text(0, 6, str(digits.target[i]))\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is the effect of the `interpolation='nearest'` parameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Modify the above script to visualize all the “8” contained in the data. Use the `cmap` option of `imshow` to display the data with a colormap that is more appropriate for visualizing intensities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Create a Gaussian Naive Bayes classifier and train it on the Digits data. Look at some of the mislabeled digits. What were their actual class, what digit were they mistaken for? Can you guess why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
